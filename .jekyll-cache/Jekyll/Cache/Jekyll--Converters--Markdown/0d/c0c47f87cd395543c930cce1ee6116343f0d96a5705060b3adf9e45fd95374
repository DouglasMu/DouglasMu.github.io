I"<h2 id="预训练模型总结">预训练模型总结</h2>

<h3 id="什么是预训练模型">什么是预训练模型？</h3>
<ul>
  <li>
    <p>预训练模型就是已经用数据集训练好了的模型。</p>
  </li>
  <li>
    <p>现在我们常用的预训练模型就是他人用常用模型，比如VGG16/19，Resnet等模型，并用大型数据集来做训练集，比如Imagenet, COCO等训练好的模型参数</p>
  </li>
</ul>

<h3 id="预训练模型有什么作用">预训练模型有什么作用？</h3>

<p>深度学习时代，为了充分训练深层模型参数并防止过拟合，通常需要更多标注数据喂养。在NLP领域，标注数据更是一个昂贵资源。PTMs从大量无标注数据中进行预训练使许多NLP任务获得显著的性能提升。总的来看，预训练模型PTMs的优势包括：</p>

<ul>
  <li>在庞大的无标注数据上进行预训练可以获取更通用的语言表示，并有利于下游任务；</li>
  <li>为模型提供了一个更好的初始化参数，在目标任务上具备更好的泛化性能、并加速收敛；</li>
  <li>是一种有效的正则化手段，避免在小数据集上过拟合（一个随机初始化的深层模型容易对小数据集过拟合）；</li>
</ul>
:ET